{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Boosting for Estimating Nuisance Parameters in GRF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DGP from the GRF Github ReadMe, I evaluated three methods of predicting E(Y|X) and E(W|X) for input in grf's causal forest: \n",
    "\n",
    "- Using a single random forest (existing implementation) \n",
    "- Using boosted regression trees (common boosting format)\n",
    "- Using boosted random forests with learning rate of 1 (as in Stefan's email) \n",
    "\n",
    "I evaluate each method using the MSE of Y.hat and E(Y|X), of W.hat and E(W|X), and of Tau.hat and TAU from the resulting causal forest, for each of the three methodologies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'mse.y.rf' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'mse.y.rf' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "mse.y = c(mse.y.rf, mse.y.boost,mse.y.both)\n",
    "mse.w = c(mse.w.rf,mse.w.boost,mse.w.both)\n",
    "mse.tau = c(mse.tau.rf,mse.tau.boost,mse.tau.both)\n",
    "data.frame(method=c(\"Random Forest\",\"Boosted Trees\", \"Boosted Forests\"),mse.y= mse.y,mse.w=mse.w,mse.tau=mse.tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosted forests improve estimation of E(Y|X) significantly. The estimation of E(W|X) improves vs random forests but not vs boosted trees. The MSE of Tau actually increases from random forests to boosted forests. \n",
    "\n",
    "The rest of the notebook contains the code and further details on the results. I also print the results for test_calibration for each of the three methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I have relied on as simple R implementation of boosted forests with shrinkage of 1 to estimate Y.hat and W.hat. If we were to add this functionality to GRF, I likely would write a C++ implementation using the existing regression_tree function in GRF and user-specified boosting-specific parameters (like learning rate and the number of forests used). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded gbm 2.1.4\n"
     ]
    }
   ],
   "source": [
    "library(gbm)\n",
    "library(grf)\n",
    "set.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Baseline using regression_forest\n",
    "Modified this DGP from GRF Github Readme.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500; p = 10\n",
    "X = matrix(rnorm(n * p), n, p)\n",
    "TAU = 1 / (1 + exp(-X[, 3]))\n",
    "E.W = 1 / (1 + exp(-X[, 1] - X[, 2]))\n",
    "W = rbinom(n ,1, E.W)\n",
    "E.Y = pmax(X[, 2] + X[, 3], 0) + rowMeans(X[, 4:6]) / 2 + W * TAU\n",
    "Y = E.Y + rnorm(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10\n",
      " $ serialized.forest: raw [1:13156560] d0 07 00 00 ...\n",
      " $ num.trees        : num 2000\n",
      " $ min.node.size    : num 1\n",
      " $ ci.group.size    : num 2\n",
      " $ X.orig           : num [1:500, 1:10] 0.0187 -0.1843 -1.3713 -0.5992 0.2945 ...\n",
      " $ Y.orig           : int [1:500] 0 0 0 0 1 1 0 1 0 0 ...\n",
      " $ clusters         : num(0) \n",
      " $ tunable.params   : Named num [1:5] 0.5 1 6 0.152 2.266\n",
      "  ..- attr(*, \"names\")= chr [1:5] \"sample.fraction\" \"min.node.size\" \"mtry\" \"alpha\" ...\n",
      " $ predictions      : num [1:500] 0.535 0.383 0.302 0.38 0.624 ...\n",
      " $ debiased.error   : num [1:500] 0.2857 0.1465 0.0913 0.1443 0.1409 ...\n",
      " - attr(*, \"class\")= chr [1:2] \"regression_forest\" \"grf\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>sample.fraction</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>min.node.size</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>mtry</dt>\n",
       "\t\t<dd>6</dd>\n",
       "\t<dt>alpha</dt>\n",
       "\t\t<dd>0.151818284648471</dd>\n",
       "\t<dt>imbalance.penalty</dt>\n",
       "\t\t<dd>2.26621415267844</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[sample.fraction] 0.5\n",
       "\\item[min.node.size] 1\n",
       "\\item[mtry] 6\n",
       "\\item[alpha] 0.151818284648471\n",
       "\\item[imbalance.penalty] 2.26621415267844\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "sample.fraction\n",
       ":   0.5min.node.size\n",
       ":   1mtry\n",
       ":   6alpha\n",
       ":   0.151818284648471imbalance.penalty\n",
       ":   2.26621415267844\n",
       "\n"
      ],
      "text/plain": [
       "  sample.fraction     min.node.size              mtry             alpha \n",
       "        0.5000000         1.0000000         6.0000000         0.1518183 \n",
       "imbalance.penalty \n",
       "        2.2662142 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest.W = regression_forest(X, W, tune.parameters = TRUE)\n",
    "W.hat = predict(forest.W)$predictions\n",
    "\n",
    "forest.Y = regression_forest(X, Y, tune.parameters = TRUE)\n",
    "Y.hat = predict(forest.Y)$predictions\n",
    "\n",
    "str(forest.W)\n",
    "forest.W$tunable.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>'hi'</li>\n",
       "\t<li>NULL</li>\n",
       "\t<li>'bye'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 'hi'\n",
       "\\item NULL\n",
       "\\item 'bye'\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 'hi'\n",
       "2. NULL\n",
       "3. 'bye'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] \"hi\"\n",
       "\n",
       "[[2]]\n",
       "NULL\n",
       "\n",
       "[[3]]\n",
       "[1] \"bye\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.forest = causal_forest(X, Y, W,\n",
    "                           W.hat = W.hat, Y.hat = Y.hat,\n",
    "                           tune.parameters = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Best linear fit using forest predictions (on held-out data)\n",
       "as well as the mean forest prediction as regressors, along\n",
       "with heteroskedasticity-robust (HC3) SEs:\n",
       "\n",
       "                               Estimate Std. Error t value  Pr(>|t|)    \n",
       "mean.forest.prediction          1.01628    0.16459  6.1746 1.377e-09 ***\n",
       "differential.forest.prediction  0.49438    0.78946  0.6262    0.5315    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_calibration(tau.forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.hat.forest = predict(tau.forest)$predictions\n",
    "mse.tau.rf = mean((TAU - tau.hat.forest)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Boosted trees don't work as well as the random forest regression alone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>null device:</strong> 1"
      ],
      "text/latex": [
       "\\textbf{null device:} 1"
      ],
      "text/markdown": [
       "**null device:** 1"
      ],
      "text/plain": [
       "null device \n",
       "          1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev.off() \n",
    "boost.Y = gbm(formula = Y~ .,\n",
    "              distribution = \"gaussian\",\n",
    "              data = data.frame(Y=Y,X=X),\n",
    "                 n.trees = 2000,\n",
    "                  shrinkage = 0.1, \n",
    "                  cv.folds = 5,\n",
    "                  n.cores = 1)\n",
    "\n",
    "Y.hat.boost = predict(object=boost.Y,n.trees=gbm.perf(boost.Y),type=\"response\")\n",
    "\n",
    "boost.W = gbm(formula = W~ .,\n",
    "              distribution = \"bernoulli\",\n",
    "              data = data.frame(W=W,X=X),\n",
    "                 n.trees = 2000,\n",
    "                  shrinkage = 0.1, \n",
    "                  cv.folds = 5,\n",
    "                  n.cores = 1)\n",
    "\n",
    "W.hat.boost = predict(object=boost.W,n.trees=gbm.perf(boost.W),type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost.tau.forest = causal_forest(X,Y,W,\n",
    "                                W.hat=W.hat.boost,Y.hat=Y.hat.boost,\n",
    "                                tune.parameters = TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.y.rf = mean((Y.hat-E.Y)^2)\n",
    "mse.y.boost = mean((Y.hat.boost-E.Y)^2)\n",
    "\n",
    "mse.w.rf = mean((W.hat-E.W)^2)\n",
    "mse.w.boost = mean((W.hat.boost-E.W)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Best linear fit using forest predictions (on held-out data)\n",
       "as well as the mean forest prediction as regressors, along\n",
       "with heteroskedasticity-robust (HC3) SEs:\n",
       "\n",
       "                                Estimate Std. Error t value  Pr(>|t|)    \n",
       "mean.forest.prediction           0.91374    0.17411  5.2480  2.28e-07 ***\n",
       "differential.forest.prediction -57.48519    6.51384 -8.8251 < 2.2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_calibration(boost.tau.forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.hat.forest.boost = predict(boost.tau.forest)$predictions\n",
    "mse.tau.boost = mean((TAU - tau.hat.forest.boost)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find that the differential.forest.prediction is lower using boosting of regression trees compared to when the random forests are used to predict Y.hat and W.hat. The prediction of E.Y is worse as well while the prediction of E.W. is a bit better for forests. The prediction of tau is substantially worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosted random forests have mixed results vs random forests alone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_forest_predictions <- function(Y,X,num_trees) {\n",
    "    \n",
    "    forest_1 = regression_forest(X,Y)\n",
    "    e.hat = forest_1$predictions\n",
    "    e = Y- e.hat\n",
    "    Y.hat = e.hat\n",
    "\n",
    "    for (i in 2:num_trees) {\n",
    "        forest = regression_forest(X,e)\n",
    "        e.hat = forest$predictions\n",
    "        e = e - e.hat \n",
    "        Y.hat = Y.hat+ e.hat \n",
    "    }\n",
    "    return(Y.hat)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.hat.both = boosted_forest_predictions(Y,X,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.hat.both = boosted_forest_predictions(W,X,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse.y.both = mean((Y.hat.both-E.Y)^2)\n",
    "mse.w.both = mean((W.hat.both - E.W)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Best linear fit using forest predictions (on held-out data)\n",
       "as well as the mean forest prediction as regressors, along\n",
       "with heteroskedasticity-robust (HC3) SEs:\n",
       "\n",
       "                                Estimate Std. Error t value  Pr(>|t|)    \n",
       "mean.forest.prediction           0.91374    0.17411  5.2480  2.28e-07 ***\n",
       "differential.forest.prediction -57.48519    6.51384 -8.8251 < 2.2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "both.tau.forest = causal_forest(X,Y,W,\n",
    "                                W.hat=W.hat.both,Y.hat=Y.hat.both,\n",
    "                                tune.parameters = TRUE) \n",
    "test_calibration(boost.tau.forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.hat.forest.both = predict(both.tau.forest)$predictions\n",
    "mse.tau.both = mean((TAU - tau.hat.forest.both)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0286685258010365"
      ],
      "text/latex": [
       "0.0286685258010365"
      ],
      "text/markdown": [
       "0.0286685258010365"
      ],
      "text/plain": [
       "[1] 0.02866853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
